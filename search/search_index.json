{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"terminal_sync Overview terminal_sync is a standalone tool for logging Bash and PowerShell commands to GhostWriter automatically. The provided Bash script and PowerShell module register pre-exec and post-exec hooks that capture and send information about executed commands to the terminal_sync server for additional processing and enrichment. Once properly configured, any commands that meet the configured logging criteria (e.g., contain a specific keyword) are sent to GhostWriter. Features Automatic Shell Logging Logs Bash and PowerShell commands directly to GhostWriter based on a configurable keyword list Export Log Entries to CSV Saves failed (or optionally all) command log entries to JSON files that can be converted to CSV and imported into GhostWriter Supports off-line logging Command Timestamps Displays execution and completion timestamps for each command Useful reference for commands not configured to auto-log In-line Descriptions Supports adding a description to the end of a command Allows users to force an individual command to be logged Maintains flow by keeping users at the command-line Simple Configuration Easy setup and configuration using YAML config file and/or environment variables Management Commands Ability to enable/disable terminal_sync or change the verbosity for an individual session Known Limitations Background jobs (i.e., Bash commands ending with & and PowerShell Start-Job commands) will always be reported as successful since the post-exec hook runs when the prompt returns, which happens before the command completes. Bash Limitations Compound commands (i.e., multiple commands joined by && ) run in the background will not be logged These commands trigger the precmd (i.e., post-exec) hook but not the preexec hook; however, the current post-exec implementation relies on a variable set in the pre-exec hook to prevent logging duplicate entries when a user submits an empty line Local vs Remote Usage The terminal_sync server is intended to be run locally and therefore does not include authentication or encryption. Should you choose to run the server on a remote host, it is highly recommended that you run it on localhost and use an SSH forward tunnel, or similar mechanism, to access it. Similarly, terminal_sync was (mostly) designed with a single user per instance in mind. The one exception is that if the OPERATOR environment variable is set within a client shell session, this value will override the operator setting on the server, thus allowing multiple users to share a terminal_sync server. That said, the server itself only supports a single API key / token per instance, so make sure all users with access to the server are authorized for that level of access to GhostWriter.","title":"Home"},{"location":"#terminal_sync","text":"","title":"terminal_sync"},{"location":"#overview","text":"terminal_sync is a standalone tool for logging Bash and PowerShell commands to GhostWriter automatically. The provided Bash script and PowerShell module register pre-exec and post-exec hooks that capture and send information about executed commands to the terminal_sync server for additional processing and enrichment. Once properly configured, any commands that meet the configured logging criteria (e.g., contain a specific keyword) are sent to GhostWriter.","title":"Overview"},{"location":"#features","text":"Automatic Shell Logging Logs Bash and PowerShell commands directly to GhostWriter based on a configurable keyword list Export Log Entries to CSV Saves failed (or optionally all) command log entries to JSON files that can be converted to CSV and imported into GhostWriter Supports off-line logging Command Timestamps Displays execution and completion timestamps for each command Useful reference for commands not configured to auto-log In-line Descriptions Supports adding a description to the end of a command Allows users to force an individual command to be logged Maintains flow by keeping users at the command-line Simple Configuration Easy setup and configuration using YAML config file and/or environment variables Management Commands Ability to enable/disable terminal_sync or change the verbosity for an individual session","title":"Features"},{"location":"#known-limitations","text":"Background jobs (i.e., Bash commands ending with & and PowerShell Start-Job commands) will always be reported as successful since the post-exec hook runs when the prompt returns, which happens before the command completes.","title":"Known Limitations"},{"location":"#bash-limitations","text":"Compound commands (i.e., multiple commands joined by && ) run in the background will not be logged These commands trigger the precmd (i.e., post-exec) hook but not the preexec hook; however, the current post-exec implementation relies on a variable set in the pre-exec hook to prevent logging duplicate entries when a user submits an empty line","title":"Bash Limitations"},{"location":"#local-vs-remote-usage","text":"The terminal_sync server is intended to be run locally and therefore does not include authentication or encryption. Should you choose to run the server on a remote host, it is highly recommended that you run it on localhost and use an SSH forward tunnel, or similar mechanism, to access it. Similarly, terminal_sync was (mostly) designed with a single user per instance in mind. The one exception is that if the OPERATOR environment variable is set within a client shell session, this value will override the operator setting on the server, thus allowing multiple users to share a terminal_sync server. That said, the server itself only supports a single API key / token per instance, so make sure all users with access to the server are authorized for that level of access to GhostWriter.","title":"Local vs Remote Usage"},{"location":"architecture/","text":"terminal_sync Architecture This page provides additional details about how terminal_sync works and is intended for those who are: Interested in contributing to the project Passionately curious Design Evolution terminal_sync began life as a prototype intended specifically for capturing command-line tools, such as Impacket scripts, run with proxychains . The original version was a Python script called directly from the Bash pre-exec hook. Unfortunately, this had several limitations. It only supported commands run via proxychains It only supported Bash The lack of a post-exec hook meant it couldn't capture when a command completed or its success/failure status There was no way to provide a description The second iteration set out to address these issues. The first challenge was how to save state so that the completion time and output of a command could be matched to the original execution, thus allowing the initial log entry to be updated rather than creating a near duplicate entry. There was also a concern that, as the application configuration became more complex, the overhead of loading the config each time the script was run (i.e., before and after each execution) would negatively impact performance and the overall user experience. This second iteration used a client-server model where the server, which contained the majority of the processing logic, would load the configuration once and stay running. The client would remain lightweight and naive, containing only enough logic to capture raw data and send it to the server. Additionally, the clients would be written using native capabilities (i.e., Bash and PowerShell) to minimize dependencies, both for security and ease of installation. How terminal_sync Works The current version of terminal_sync uses a client-server model. Server The terminal_sync server is a Python package consisting of four main components: Config class Defined in config.py GhostWriterClient class Defined in ghostwriter.py FastAPI server Defined in api.py Entry class Defined in log_entry.py The server must be installed or run as a module since it uses absolute imports to reference internal modules. This was done to prevent isort from grouping the internal modules into the third-party libraries import section. Config The Config class defines default settings, loads the YAML config file (if it exists), and checks for any environment variables that match defined settings. If the optional python-dotenv package is installed, environment variables will be loaded from a .env file before loading the YAML config. This is done because the path to the config file can be specified using the TERMSYNC_CONFIG variable. If TERMSYNC_CONFIG was included in the .env file but the environment variables were loaded later, the wrong config file would be loaded, which would likely confuse users. All other environment variables are evaluated after, and therefore override values from, the YAML config file. Finally, some additional validation is performed and the config object is returned. GhostWriter Client The GhostWriter client is largely a consolidation of the REST-based mythic-sync and GraphQL-based mythic_sync projects with some logic to determine which flow to use based on which API key was provided. Additionally, the exception handling was moved to the API server to allow it to send error messages back to the client. API Server The API server uses FastAPI to create two REST endpoints, POST /commands/ and PUT /commands/ , intended to create and update command log entries, respectively. In practice, the update endpoint will also create an entry if a matching one is not found in the internal buffer; this is to increase the likelihood of a command being logged successfully, even if the initial creation attempt failed. Since both endpoints contain nearly identical logic, the majority of the work is done in the shared log_command() function. This function checks whether the input command contains any keywords that would trigger logging. If so, the description is split from the command (if applicable), an Entry object is either created or retrieved from the internal buffer and updated, then the Entry object is sent to the GhostWriter client, which sends it to GhostWriter. If the submission fails, or if the config specifies all logs should be saved, the Entry is passed to the save_log() function which saves it as a JSON object. Entry The Entry class is mostly responsible for encapsulating data as it's passed around the application but contains some logic to normalize and return it in different formats for the distinct REST and GraphQL APIs. Clients The current clients, written using Bash and PowerShell, are integrated into their respective hook code and implement similar logic. They define client-side configuration settings at the top, include functions to enable/disable hooking and control verbosity, and define the hook functions themselves. The hook functions capture the raw data such as the executed command and timestamps, as well as operator and source host if the environment variables are set. This data is then packaged as a JSON object and sent to the server. The response is received and optionally printed, depending on the verbosity settings. The Bash client uses bash-preexec to create the preexec and precmd (i.e., post-exec) hook points and uses jq to construct and parse the JSON objects exchanged with the server. The PowerShell client overrides the PSConsoleHostReadLine and Prompt functions to create pre-exec and post-exec hooks. Execution Flow The terminal_sync server is started by executing python -m terminal_sync either directly or by running pdm serve . This runs the __main__.py module, which parses any host and port arguments and calls the run() function in api.py . When api.py is loaded, it instantiates a Config object, a GhostWriterClient object, and an instance of FastAPI. The run() method starts uvicorn to host the FastAPI instance. When a user runs a command, the client hook code intercepts it, packages the command with additional metadata (including a UUID), and sends it to the creation endpoint on the terminal_sync server. The pre_exec() function calls log_command() , which checks whether the command contains any of the configured keywords. If so, a new Entry object is created, added to an internal buffer, and sent to the create_log() method of the GhostWriter client. The GhostWriter client then uses either _create_entry_graphql() or _create_entry_rest() , depending on which API key was specified, to send the command data to GhostWriter. If succcessful, GhostWriter returns a JSON object containing the ID of the GhostWriter log entry. The GhostWriter client passes this ID back to log_command() where it is added to the Entry object. The Entry object and a success message are returned to the pre_exec() function, triggering the finally clause in log_command() . If the connection to GhostWriter had failed or if the application is configured to save all logs, log_command() will call save_log() to write the Entry data to a JSON file. Back in pre_exec() , the message is returned to the terminal_sync client. The terminal_sync client optionally displays the message, depending on the verbosity settings, and returns, allowing the command to execute. When the command completes, the client hook code intercepts execution again, records the exit status of the command, retrieves additional information about the command from the shell history, packages it all up, and sends it to the update endpoint on the terminal_sync server. The post_exec() function calls log_command() , which uses the UUID string sent with the command to retrieve the previously created Entry object from the internal buffer. The Entry is updated and sent to the GhostWriter client's update_log() method, which maps to either _update_entry_graphql() or _update_entry_rest() . The remainder of the flow is essentially identical to the creation flow, except, when execution returns to post_exec() , the Entry is removed from the internal buffer, since it has been processed.","title":"Architecture"},{"location":"architecture/#terminal_sync-architecture","text":"This page provides additional details about how terminal_sync works and is intended for those who are: Interested in contributing to the project Passionately curious","title":"terminal_sync Architecture"},{"location":"architecture/#design-evolution","text":"terminal_sync began life as a prototype intended specifically for capturing command-line tools, such as Impacket scripts, run with proxychains . The original version was a Python script called directly from the Bash pre-exec hook. Unfortunately, this had several limitations. It only supported commands run via proxychains It only supported Bash The lack of a post-exec hook meant it couldn't capture when a command completed or its success/failure status There was no way to provide a description The second iteration set out to address these issues. The first challenge was how to save state so that the completion time and output of a command could be matched to the original execution, thus allowing the initial log entry to be updated rather than creating a near duplicate entry. There was also a concern that, as the application configuration became more complex, the overhead of loading the config each time the script was run (i.e., before and after each execution) would negatively impact performance and the overall user experience. This second iteration used a client-server model where the server, which contained the majority of the processing logic, would load the configuration once and stay running. The client would remain lightweight and naive, containing only enough logic to capture raw data and send it to the server. Additionally, the clients would be written using native capabilities (i.e., Bash and PowerShell) to minimize dependencies, both for security and ease of installation.","title":"Design Evolution"},{"location":"architecture/#how-terminal_sync-works","text":"The current version of terminal_sync uses a client-server model.","title":"How terminal_sync Works"},{"location":"architecture/#server","text":"The terminal_sync server is a Python package consisting of four main components: Config class Defined in config.py GhostWriterClient class Defined in ghostwriter.py FastAPI server Defined in api.py Entry class Defined in log_entry.py The server must be installed or run as a module since it uses absolute imports to reference internal modules. This was done to prevent isort from grouping the internal modules into the third-party libraries import section.","title":"Server"},{"location":"architecture/#config","text":"The Config class defines default settings, loads the YAML config file (if it exists), and checks for any environment variables that match defined settings. If the optional python-dotenv package is installed, environment variables will be loaded from a .env file before loading the YAML config. This is done because the path to the config file can be specified using the TERMSYNC_CONFIG variable. If TERMSYNC_CONFIG was included in the .env file but the environment variables were loaded later, the wrong config file would be loaded, which would likely confuse users. All other environment variables are evaluated after, and therefore override values from, the YAML config file. Finally, some additional validation is performed and the config object is returned.","title":"Config"},{"location":"architecture/#ghostwriter-client","text":"The GhostWriter client is largely a consolidation of the REST-based mythic-sync and GraphQL-based mythic_sync projects with some logic to determine which flow to use based on which API key was provided. Additionally, the exception handling was moved to the API server to allow it to send error messages back to the client.","title":"GhostWriter Client"},{"location":"architecture/#api-server","text":"The API server uses FastAPI to create two REST endpoints, POST /commands/ and PUT /commands/ , intended to create and update command log entries, respectively. In practice, the update endpoint will also create an entry if a matching one is not found in the internal buffer; this is to increase the likelihood of a command being logged successfully, even if the initial creation attempt failed. Since both endpoints contain nearly identical logic, the majority of the work is done in the shared log_command() function. This function checks whether the input command contains any keywords that would trigger logging. If so, the description is split from the command (if applicable), an Entry object is either created or retrieved from the internal buffer and updated, then the Entry object is sent to the GhostWriter client, which sends it to GhostWriter. If the submission fails, or if the config specifies all logs should be saved, the Entry is passed to the save_log() function which saves it as a JSON object.","title":"API Server"},{"location":"architecture/#entry","text":"The Entry class is mostly responsible for encapsulating data as it's passed around the application but contains some logic to normalize and return it in different formats for the distinct REST and GraphQL APIs.","title":"Entry"},{"location":"architecture/#clients","text":"The current clients, written using Bash and PowerShell, are integrated into their respective hook code and implement similar logic. They define client-side configuration settings at the top, include functions to enable/disable hooking and control verbosity, and define the hook functions themselves. The hook functions capture the raw data such as the executed command and timestamps, as well as operator and source host if the environment variables are set. This data is then packaged as a JSON object and sent to the server. The response is received and optionally printed, depending on the verbosity settings. The Bash client uses bash-preexec to create the preexec and precmd (i.e., post-exec) hook points and uses jq to construct and parse the JSON objects exchanged with the server. The PowerShell client overrides the PSConsoleHostReadLine and Prompt functions to create pre-exec and post-exec hooks.","title":"Clients"},{"location":"architecture/#execution-flow","text":"The terminal_sync server is started by executing python -m terminal_sync either directly or by running pdm serve . This runs the __main__.py module, which parses any host and port arguments and calls the run() function in api.py . When api.py is loaded, it instantiates a Config object, a GhostWriterClient object, and an instance of FastAPI. The run() method starts uvicorn to host the FastAPI instance. When a user runs a command, the client hook code intercepts it, packages the command with additional metadata (including a UUID), and sends it to the creation endpoint on the terminal_sync server. The pre_exec() function calls log_command() , which checks whether the command contains any of the configured keywords. If so, a new Entry object is created, added to an internal buffer, and sent to the create_log() method of the GhostWriter client. The GhostWriter client then uses either _create_entry_graphql() or _create_entry_rest() , depending on which API key was specified, to send the command data to GhostWriter. If succcessful, GhostWriter returns a JSON object containing the ID of the GhostWriter log entry. The GhostWriter client passes this ID back to log_command() where it is added to the Entry object. The Entry object and a success message are returned to the pre_exec() function, triggering the finally clause in log_command() . If the connection to GhostWriter had failed or if the application is configured to save all logs, log_command() will call save_log() to write the Entry data to a JSON file. Back in pre_exec() , the message is returned to the terminal_sync client. The terminal_sync client optionally displays the message, depending on the verbosity settings, and returns, allowing the command to execute. When the command completes, the client hook code intercepts execution again, records the exit status of the command, retrieves additional information about the command from the shell history, packages it all up, and sends it to the update endpoint on the terminal_sync server. The post_exec() function calls log_command() , which uses the UUID string sent with the command to retrieve the previously created Entry object from the internal buffer. The Entry is updated and sent to the GhostWriter client's update_log() method, which maps to either _update_entry_graphql() or _update_entry_rest() . The remainder of the flow is essentially identical to the creation flow, except, when execution returns to post_exec() , the Entry is removed from the internal buffer, since it has been processed.","title":"Execution Flow"},{"location":"developer_guide/","text":"Developer Guide Thank you for your interest in contributing to terminal_sync! If you haven't already done so, we recommend you start by learning how terminal_sync has evolved and how terminal_sync currently works . This will help explain some of the design decisions and orient you to the codebase. When you're ready to start coding, you'll follow this general process: Fork the repo Clone your fork Setup your environment Install PDM Use PDM to install all dependencies Install pre-commit Write code or make changes Write tests Run tests Update documentation and the CHANGELOG Commit code (...fix any pre-commit failures, re-add, and re-commit code) Submit a pull request Tools Git Python 3.10+ and pip PDM This is a package dependency manager and general project management utility, similar to Poetry pre-commit A framework for managing multi-language pre-commit hooks This is used to automate tedious tasks and enforce consistent standards Code editor Visual Studio Code with the Python extension (recommended) Setting Up Your Environment PDM # Install PDM pip install pdm # Install all dependencies pdm install # Install pre-commit hooks pdm run pre-commit install Use pdm list to display a list of installed dependencies and their versions or pdm list --graph to display this information in tree format with sub-dependencies appropriately nested. Integrated Development Environment (IDE) While it's not required, we recommend using Visual Studio Code (VS Code) as your IDE. To configure VS Code, create a file named terminal_sync.code-workspace in the root project directory. Add the following to it, then run pdm code . This will start your VS Code instance within the PDM environment, allowing it to find locally installed packages without additional configuration. { \"folders\": [ { \"path\": \".\" } ], \"settings\": { \"python.defaultInterpreterPath\": \".\\\\.venv\\\\Scripts\\\\python.exe\" } } While developing, you'll typically run the server through your IDE to enable features like the debugger; however, if you need to start the server from command-line, use pdm serve or pdm run python -m terminal_sync . pytest To run tests, use pdm test or pdm run pytest . pre-commit pre-commit, as the name may suggest, only checks files that are tracked by git; be sure to git add any relevant files before running the checks. The pre-commit configuration and hooks are contained in .pre-commit-config.yaml . By default, pre-commit will run when you make a commit; however, you can also run the checks manually using pdm check or pdm run pre-commit run --all-files . Documentation The terminal_sync documentation is written in Markdown, located under docs/ , built using mkdocs , hosted using GitHub Pages, and automatically deployed using a GitHub Actions workflow ( .github/workflows/documentation.yml ). To view the documentation locally, run pdm docs or pdm run mkdocs serve [--dev-addr <IP>:<PORT>] . Conventions Whenever possible, use pyproject.toml for all external tool configurations, including pre-commit hooks. This centralizes the configuration settings and ensures consistency in case developers run the same tool manually and with pre-commit. Please refer to the Style Guide for stylistic conventions.","title":"Developer Guide"},{"location":"developer_guide/#developer-guide","text":"Thank you for your interest in contributing to terminal_sync! If you haven't already done so, we recommend you start by learning how terminal_sync has evolved and how terminal_sync currently works . This will help explain some of the design decisions and orient you to the codebase. When you're ready to start coding, you'll follow this general process: Fork the repo Clone your fork Setup your environment Install PDM Use PDM to install all dependencies Install pre-commit Write code or make changes Write tests Run tests Update documentation and the CHANGELOG Commit code (...fix any pre-commit failures, re-add, and re-commit code) Submit a pull request","title":"Developer Guide"},{"location":"developer_guide/#tools","text":"Git Python 3.10+ and pip PDM This is a package dependency manager and general project management utility, similar to Poetry pre-commit A framework for managing multi-language pre-commit hooks This is used to automate tedious tasks and enforce consistent standards Code editor Visual Studio Code with the Python extension (recommended)","title":"Tools"},{"location":"developer_guide/#setting-up-your-environment","text":"","title":"Setting Up Your Environment"},{"location":"developer_guide/#pdm","text":"# Install PDM pip install pdm # Install all dependencies pdm install # Install pre-commit hooks pdm run pre-commit install Use pdm list to display a list of installed dependencies and their versions or pdm list --graph to display this information in tree format with sub-dependencies appropriately nested.","title":"PDM"},{"location":"developer_guide/#integrated-development-environment-ide","text":"While it's not required, we recommend using Visual Studio Code (VS Code) as your IDE. To configure VS Code, create a file named terminal_sync.code-workspace in the root project directory. Add the following to it, then run pdm code . This will start your VS Code instance within the PDM environment, allowing it to find locally installed packages without additional configuration. { \"folders\": [ { \"path\": \".\" } ], \"settings\": { \"python.defaultInterpreterPath\": \".\\\\.venv\\\\Scripts\\\\python.exe\" } } While developing, you'll typically run the server through your IDE to enable features like the debugger; however, if you need to start the server from command-line, use pdm serve or pdm run python -m terminal_sync .","title":"Integrated Development Environment (IDE)"},{"location":"developer_guide/#pytest","text":"To run tests, use pdm test or pdm run pytest .","title":"pytest"},{"location":"developer_guide/#pre-commit","text":"pre-commit, as the name may suggest, only checks files that are tracked by git; be sure to git add any relevant files before running the checks. The pre-commit configuration and hooks are contained in .pre-commit-config.yaml . By default, pre-commit will run when you make a commit; however, you can also run the checks manually using pdm check or pdm run pre-commit run --all-files .","title":"pre-commit"},{"location":"developer_guide/#documentation","text":"The terminal_sync documentation is written in Markdown, located under docs/ , built using mkdocs , hosted using GitHub Pages, and automatically deployed using a GitHub Actions workflow ( .github/workflows/documentation.yml ). To view the documentation locally, run pdm docs or pdm run mkdocs serve [--dev-addr <IP>:<PORT>] .","title":"Documentation"},{"location":"developer_guide/#conventions","text":"Whenever possible, use pyproject.toml for all external tool configurations, including pre-commit hooks. This centralizes the configuration settings and ensures consistency in case developers run the same tool manually and with pre-commit. Please refer to the Style Guide for stylistic conventions.","title":"Conventions"},{"location":"quickstart/","text":"Quickstart The following sections provide the minimum steps required to configure terminal_sync without all those pesky explanations. If you encounter problems or want additional details, please refer to the Setup page. These directions assume: You have the following software installed: Git Python 3.10+ and pip OR Docker and Docker Compose You will be running the terminal_sync server locally You will be capturing commands from a local Bash session on Linux or a local PowerShell session on Windows # Step 1: Get the Code git clone https://github.com/breakid/terminal_sync cd terminal_sync # Step 2: Configure the Server cp config_template.yaml config.yaml # ACTION: Modify the gw_url, gw_oplog_id, and gw_api_key_graphql or # gw_api_key_rest settings to match your environment # Step 3: Run the Server # Step 3a: Docker touch terminal_sync.log # On Linux $null > terminal_sync.log # On Windows docker-compose up -d # Step 3b: PDM pip install pdm pdm install --prod pdm serve # Step 4: Setup Terminal Hooks # Bash: source terminal_sync.sh # ACTION: Answer the prompts that appear on first run # PowerShell: Import-Module terminal_sync.psm1","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"The following sections provide the minimum steps required to configure terminal_sync without all those pesky explanations. If you encounter problems or want additional details, please refer to the Setup page. These directions assume: You have the following software installed: Git Python 3.10+ and pip OR Docker and Docker Compose You will be running the terminal_sync server locally You will be capturing commands from a local Bash session on Linux or a local PowerShell session on Windows # Step 1: Get the Code git clone https://github.com/breakid/terminal_sync cd terminal_sync # Step 2: Configure the Server cp config_template.yaml config.yaml # ACTION: Modify the gw_url, gw_oplog_id, and gw_api_key_graphql or # gw_api_key_rest settings to match your environment # Step 3: Run the Server # Step 3a: Docker touch terminal_sync.log # On Linux $null > terminal_sync.log # On Windows docker-compose up -d # Step 3b: PDM pip install pdm pdm install --prod pdm serve # Step 4: Setup Terminal Hooks # Bash: source terminal_sync.sh # ACTION: Answer the prompts that appear on first run # PowerShell: Import-Module terminal_sync.psm1","title":"Quickstart"},{"location":"setup/","text":"Setup Introduction The following is a high-level overview of the steps required to setup terminal_sync. Additional details are provided in the sections below. Get the Code Configure the Server Run the Server Docker PDM Setup Terminal Hooks Bash PowerShell If you encounter problems, please refer to the Troubleshooting page. Prerequisites : These instructions assume you have either Python 3.10+ and pip or Docker and Docker Compose installed. 1. Get the Code Use git to clone this repo, or download and extract a zip archive of the files. git clone https://github.com/breakid/terminal_sync cd terminal_sync All subsequent instructions are provided from the context of the root project directory. 2. Configure the Server The server can be configured using a YAML config file, environment variables, or a combination thereof, with environment variables overriding config file values. By default, terminal_sync will look for config.yaml in the current working directory (relative to where you run the server). You may use the TERMSYNC_CONFIG environment variable to specify an alternate config file path. An example configuration file, config_template.yaml , is provided and contains comments that explain the purpose of each setting. To create a new config file, we recommend that you copy this template and edit the copy to meet your needs. cp config_template.yaml config.yaml Environment variables match the upper-case version (on case-sensitive systems) of the setting name found in the config file. For instance, the config file settings gw_url and gw_oplog_id become the environment variables GW_URL and GW_OPLOG_ID . The values are parsed as YAML, so all options found in the config file are supported, including complex structures such as lists and dictionaries. The server will automatically load any environment variables defined in a .env file. At a minimum, the gw_url , gw_oplog_id , and at least one of gw_api_key_graphql or gw_api_key_rest must be configured for terminal_sync to log to GhostWriter. If both API keys are set, terminal_sync will use GraphQL by default. Note : To allow terminal_sync to be used off-line or independent of GhostWriter, the server will display a warning but start successfully even if these values are not provided. In this case, local logging will be enabled by default. 3. Run the Server The server can be run as a Docker container or using PDM . Docker While there is not currently a pre-built image, a Dockerfile and docker-compose.yaml config are provided to simplify the build process. The default Compose config assumes: You created a config.yaml file in the previous step You have a terminal_sync.log file in the root project directory This will be bind mounted into the container to persist application logs Use touch terminal_sync.log in Bash or $null > terminal_sync.log in PowerShell to initialize this file If you prefer to use environment variables rather than a config file, uncomment the environment section, fill in the appropriate values, and comment out or remove the config.yaml volume entry. Note : If the config.yaml or terminal_sync.log files do not exist, Compose will create an empty directory for each missing source path. If you choose not to use these volumes, comment out or remove them from the Compose config. Once you have made any desired modifications to the Compose config, use the following command to start the server, optionally in detached mode ( -d ). On first run, Docker Compose should automatically build a local copy of the image, which will be used for subsequent executions. docker-compose up -d If you need to rebuild the image, such as after making or pulling changes to the code, add the --build flag to the command. docker-compose up -d --build When running in detached mode, you won't see any output from the container. Use the following command to view the logs; this is especially useful for troubleshooting. docker-compose logs If the build fails, you may need to build the image manually using Docker. docker build --network=host --tag=terminal_sync:latest . To stop the server, run the following: docker-compose down PDM If you have Python 3.10 or later, you can run the server using PDM. # Install PDM pip install pdm # Use PDM to install the production dependencies and terminal_sync package pdm install --prod # Use the PDM 'serve' script to run the application with uvicorn # Note: This will run the server in the foreground, occupying your terminal pdm serve To stop the server, press CTRL+C . If that doesn't work, kill the uvicorn process manually. 4. Setup Terminal Hooks Bash Review and optionally edit the Configuration Settings section at the top of terminal_sync.sh Run source ./terminal_sync.sh Note : This must be done in each new bash session You will be prompted to install any missing dependencies On first run, you will also be prompted whether you want to install the hooks (i.e., automatically source the script in each new session) If you decide later that you want to install the hooks, just append source '<PATH_TO>/terminal_sync.sh' to your ~/.bashrc file. PowerShell Review and optionally edit the Configuration Settings section at the top of terminal_sync.psm1 Run Import-Module terminal_sync.psm1 Note : This must be done in each new PowerShell session If this fails, you may need to use Set-ExecutionPolicy to allow scripts If you want to load the module automatically, run the following: # Set the execution policy to allow scripts to run # Alternatively, you can set the policy to 'Bypass' to disable all warnings Set-ExecutionPolicy Unrestricted -Scope CurrentUser # Add terminal_sync.psm1 to your PowerShell profile so it will be loaded automatically Write-Output \"Import-Module '$(Resolve-Path terminal_sync.psm1)'\" | Out-File -Append -Encoding utf8 $PROFILE","title":"Setup"},{"location":"setup/#setup","text":"","title":"Setup"},{"location":"setup/#introduction","text":"The following is a high-level overview of the steps required to setup terminal_sync. Additional details are provided in the sections below. Get the Code Configure the Server Run the Server Docker PDM Setup Terminal Hooks Bash PowerShell If you encounter problems, please refer to the Troubleshooting page. Prerequisites : These instructions assume you have either Python 3.10+ and pip or Docker and Docker Compose installed.","title":"Introduction"},{"location":"setup/#1-get-the-code","text":"Use git to clone this repo, or download and extract a zip archive of the files. git clone https://github.com/breakid/terminal_sync cd terminal_sync All subsequent instructions are provided from the context of the root project directory.","title":"1. Get the Code"},{"location":"setup/#2-configure-the-server","text":"The server can be configured using a YAML config file, environment variables, or a combination thereof, with environment variables overriding config file values. By default, terminal_sync will look for config.yaml in the current working directory (relative to where you run the server). You may use the TERMSYNC_CONFIG environment variable to specify an alternate config file path. An example configuration file, config_template.yaml , is provided and contains comments that explain the purpose of each setting. To create a new config file, we recommend that you copy this template and edit the copy to meet your needs. cp config_template.yaml config.yaml Environment variables match the upper-case version (on case-sensitive systems) of the setting name found in the config file. For instance, the config file settings gw_url and gw_oplog_id become the environment variables GW_URL and GW_OPLOG_ID . The values are parsed as YAML, so all options found in the config file are supported, including complex structures such as lists and dictionaries. The server will automatically load any environment variables defined in a .env file. At a minimum, the gw_url , gw_oplog_id , and at least one of gw_api_key_graphql or gw_api_key_rest must be configured for terminal_sync to log to GhostWriter. If both API keys are set, terminal_sync will use GraphQL by default. Note : To allow terminal_sync to be used off-line or independent of GhostWriter, the server will display a warning but start successfully even if these values are not provided. In this case, local logging will be enabled by default.","title":"2. Configure the Server"},{"location":"setup/#3-run-the-server","text":"The server can be run as a Docker container or using PDM .","title":"3. Run the Server"},{"location":"setup/#docker","text":"While there is not currently a pre-built image, a Dockerfile and docker-compose.yaml config are provided to simplify the build process. The default Compose config assumes: You created a config.yaml file in the previous step You have a terminal_sync.log file in the root project directory This will be bind mounted into the container to persist application logs Use touch terminal_sync.log in Bash or $null > terminal_sync.log in PowerShell to initialize this file If you prefer to use environment variables rather than a config file, uncomment the environment section, fill in the appropriate values, and comment out or remove the config.yaml volume entry. Note : If the config.yaml or terminal_sync.log files do not exist, Compose will create an empty directory for each missing source path. If you choose not to use these volumes, comment out or remove them from the Compose config. Once you have made any desired modifications to the Compose config, use the following command to start the server, optionally in detached mode ( -d ). On first run, Docker Compose should automatically build a local copy of the image, which will be used for subsequent executions. docker-compose up -d If you need to rebuild the image, such as after making or pulling changes to the code, add the --build flag to the command. docker-compose up -d --build When running in detached mode, you won't see any output from the container. Use the following command to view the logs; this is especially useful for troubleshooting. docker-compose logs If the build fails, you may need to build the image manually using Docker. docker build --network=host --tag=terminal_sync:latest . To stop the server, run the following: docker-compose down","title":"Docker"},{"location":"setup/#pdm","text":"If you have Python 3.10 or later, you can run the server using PDM. # Install PDM pip install pdm # Use PDM to install the production dependencies and terminal_sync package pdm install --prod # Use the PDM 'serve' script to run the application with uvicorn # Note: This will run the server in the foreground, occupying your terminal pdm serve To stop the server, press CTRL+C . If that doesn't work, kill the uvicorn process manually.","title":"PDM"},{"location":"setup/#4-setup-terminal-hooks","text":"","title":"4. Setup Terminal Hooks"},{"location":"setup/#bash","text":"Review and optionally edit the Configuration Settings section at the top of terminal_sync.sh Run source ./terminal_sync.sh Note : This must be done in each new bash session You will be prompted to install any missing dependencies On first run, you will also be prompted whether you want to install the hooks (i.e., automatically source the script in each new session) If you decide later that you want to install the hooks, just append source '<PATH_TO>/terminal_sync.sh' to your ~/.bashrc file.","title":"Bash"},{"location":"setup/#powershell","text":"Review and optionally edit the Configuration Settings section at the top of terminal_sync.psm1 Run Import-Module terminal_sync.psm1 Note : This must be done in each new PowerShell session If this fails, you may need to use Set-ExecutionPolicy to allow scripts If you want to load the module automatically, run the following: # Set the execution policy to allow scripts to run # Alternatively, you can set the policy to 'Bypass' to disable all warnings Set-ExecutionPolicy Unrestricted -Scope CurrentUser # Add terminal_sync.psm1 to your PowerShell profile so it will be loaded automatically Write-Output \"Import-Module '$(Resolve-Path terminal_sync.psm1)'\" | Out-File -Append -Encoding utf8 $PROFILE","title":"PowerShell"},{"location":"style_guide/","text":"Style Guide Consistent style is important for clean and maintainable code. Unless contradicted by the guidance below, all contributors should follow PEP 8 \u2013 Style Guide for Python Code and any other applicable PEP standards. Additionally, this project uses a variety of pre-commit hooks to automatically lint, format, and otherwise clean up code. Pull requests will not be accepted unless the pre-commit checks pass or convincing justification is provided. Line Length Lines should be 120 characters or less. We are no longer technologically limited to 80 characters per line. A 120 character limit works well with modern tools, improves readability, and makes better use of horizontal screen space, allowing developers to see more code at once. Imports Most imports should be placed at the top of the file as stated in PEP 8; however, third-party packages may be imported within the code if they are part of an optional and non-critical workflow. Users should not be required to install unnecessary packages if they don't intend to use the associated functionality, and the program should function properly without these optional packages. Each import should be on a separate line to minimize merge conflicts (see reorder_python_imports ). Imports should be grouped into (at least) three sections: Standard Libraries, Third-party Libraries, and Internal Libraries. This is enforced by the isort pre-commit hook. Comments terminal_sync uses Google Style docstrings. Click here for some examples.","title":"Style Guide"},{"location":"style_guide/#style-guide","text":"Consistent style is important for clean and maintainable code. Unless contradicted by the guidance below, all contributors should follow PEP 8 \u2013 Style Guide for Python Code and any other applicable PEP standards. Additionally, this project uses a variety of pre-commit hooks to automatically lint, format, and otherwise clean up code. Pull requests will not be accepted unless the pre-commit checks pass or convincing justification is provided.","title":"Style Guide"},{"location":"style_guide/#line-length","text":"Lines should be 120 characters or less. We are no longer technologically limited to 80 characters per line. A 120 character limit works well with modern tools, improves readability, and makes better use of horizontal screen space, allowing developers to see more code at once.","title":"Line Length"},{"location":"style_guide/#imports","text":"Most imports should be placed at the top of the file as stated in PEP 8; however, third-party packages may be imported within the code if they are part of an optional and non-critical workflow. Users should not be required to install unnecessary packages if they don't intend to use the associated functionality, and the program should function properly without these optional packages. Each import should be on a separate line to minimize merge conflicts (see reorder_python_imports ). Imports should be grouped into (at least) three sections: Standard Libraries, Third-party Libraries, and Internal Libraries. This is enforced by the isort pre-commit hook.","title":"Imports"},{"location":"style_guide/#comments","text":"terminal_sync uses Google Style docstrings. Click here for some examples.","title":"Comments"},{"location":"troubleshooting/","text":"Troubleshooting The following is a list of potential errors identified during testing and recommended methods for resolving them. Test Environments Development and testing were performed using the configurations listed below. If you encounter any problems attributable to a different environment, please submit a GitHub issue ; be sure to include a detailed description of the problem and relevant information about your environment. We can't fix what we can't replicate. Windows 11 (terminal_sync server and PowerShell hooks) Docker 20.10.24, build 297e128 Docker Compose v2.17.2 PowerShell 5.1.22621.963 Python 3.11 Debian 11 (terminal_sync server and Bash hooks) Docker version 23.0.4, build f480fb1 Docker Compose version v2.17.2 Python 3.11.3 Debian 11 (Bash hooks) Python 3.9.2 GhostWriter running over HTTPS Server Problems No GhostWriter API key specified Problem : Neither a GraphQL nor a REST API key were provided Solution : Make sure to enter a valid API key for at least one of these settings in the config.yaml file or set the GW_API_KEY_GRAPHQL or GW_API_KEY_REST environment variables. A config.yaml or terminal_sync.log directory gets created Problem : You didn't create the necessary file(s) before running the server with Docker Compose Solution : Stop the server ( docker-compose down ) Delete the config.yaml and/or terminal_sync.log directory Initalize the config.yaml and/or terminal_sync.log files (see Setup: Configure the Server ) Restart the server ( docker-compose up -d ) Client Problems Cannot connect to host ssl:False [getaddrinfo failed] Problem : terminal_sync is unable to resolve the hostname of your GhostWriter server Solution : Verify the gw_url setting contains the correct hostname Verify connectivity to your GhostWriter server (e.g., check any VPNs, SSH tunnels, etc.) Check your DNS settings Cannot connect to host ssl:False [The remote computer refused the network connection] Problem : terminal_sync can reach the GhostWriter server, but the port is blocked Solution : Verify the gw_url setting contains any applicable port numbers Check the firewall settings on your GhostWriter server Authentication hook unauthorized this request Problem : Your GraphQL token is invalid Solution : Verify your token hasn't expired Verify the token you specified is correct and complete Generate a new GraphQL token key check constraint of an insert/update permission has failed Problem : You're using the GraphQL API, and either the Oplog ID you're trying to write to doesn't exist, or you don't have permission to write to it Solution : Verify an Oplog with the specified ID exists Verify your user account is assigned to the project to which the specified Oplog belongs Authentication credentials were not provided Problem : You're using the REST API and provided an API key, but your gw_url is using http:// rather than https:// Solution : Modify your gw_url to use https:// 404, message='Not Found', url=URL('https:// /v1/graphql') Problem : While there are likely many causes for this generic issue, this was observed when using the GraphQL API and a gw_url containing http:// rather than https:// Solution : Modify your gw_url to use https://","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting","text":"The following is a list of potential errors identified during testing and recommended methods for resolving them.","title":"Troubleshooting"},{"location":"troubleshooting/#test-environments","text":"Development and testing were performed using the configurations listed below. If you encounter any problems attributable to a different environment, please submit a GitHub issue ; be sure to include a detailed description of the problem and relevant information about your environment. We can't fix what we can't replicate. Windows 11 (terminal_sync server and PowerShell hooks) Docker 20.10.24, build 297e128 Docker Compose v2.17.2 PowerShell 5.1.22621.963 Python 3.11 Debian 11 (terminal_sync server and Bash hooks) Docker version 23.0.4, build f480fb1 Docker Compose version v2.17.2 Python 3.11.3 Debian 11 (Bash hooks) Python 3.9.2 GhostWriter running over HTTPS","title":"Test Environments"},{"location":"troubleshooting/#server-problems","text":"","title":"Server Problems"},{"location":"troubleshooting/#no-ghostwriter-api-key-specified","text":"Problem : Neither a GraphQL nor a REST API key were provided Solution : Make sure to enter a valid API key for at least one of these settings in the config.yaml file or set the GW_API_KEY_GRAPHQL or GW_API_KEY_REST environment variables.","title":"No GhostWriter API key specified"},{"location":"troubleshooting/#a-configyaml-or-terminal_synclog-directory-gets-created","text":"Problem : You didn't create the necessary file(s) before running the server with Docker Compose Solution : Stop the server ( docker-compose down ) Delete the config.yaml and/or terminal_sync.log directory Initalize the config.yaml and/or terminal_sync.log files (see Setup: Configure the Server ) Restart the server ( docker-compose up -d )","title":"A config.yaml or terminal_sync.log directory gets created"},{"location":"troubleshooting/#client-problems","text":"","title":"Client Problems"},{"location":"troubleshooting/#cannot-connect-to-host-sslfalse-getaddrinfo-failed","text":"Problem : terminal_sync is unable to resolve the hostname of your GhostWriter server Solution : Verify the gw_url setting contains the correct hostname Verify connectivity to your GhostWriter server (e.g., check any VPNs, SSH tunnels, etc.) Check your DNS settings","title":"Cannot connect to host  ssl:False [getaddrinfo failed]"},{"location":"troubleshooting/#cannot-connect-to-host-sslfalse-the-remote-computer-refused-the-network-connection","text":"Problem : terminal_sync can reach the GhostWriter server, but the port is blocked Solution : Verify the gw_url setting contains any applicable port numbers Check the firewall settings on your GhostWriter server","title":"Cannot connect to host  ssl:False [The remote computer refused the network connection]"},{"location":"troubleshooting/#authentication-hook-unauthorized-this-request","text":"Problem : Your GraphQL token is invalid Solution : Verify your token hasn't expired Verify the token you specified is correct and complete Generate a new GraphQL token key","title":"Authentication hook unauthorized this request"},{"location":"troubleshooting/#check-constraint-of-an-insertupdate-permission-has-failed","text":"Problem : You're using the GraphQL API, and either the Oplog ID you're trying to write to doesn't exist, or you don't have permission to write to it Solution : Verify an Oplog with the specified ID exists Verify your user account is assigned to the project to which the specified Oplog belongs","title":"check constraint of an insert/update permission has failed"},{"location":"troubleshooting/#authentication-credentials-were-not-provided","text":"Problem : You're using the REST API and provided an API key, but your gw_url is using http:// rather than https:// Solution : Modify your gw_url to use https://","title":"Authentication credentials were not provided"},{"location":"troubleshooting/#404-messagenot-found-urlurlhttpsv1graphql","text":"Problem : While there are likely many causes for this generic issue, this was observed when using the GraphQL API and a gw_url containing http:// rather than https:// Solution : Modify your gw_url to use https://","title":"404, message='Not Found', url=URL('https:///v1/graphql')"},{"location":"updating/","text":"Updating terminal_sync Use git pull to get the latest updates or download an updated zip archive from GitHub Update the server If using Docker, run docker-compose up -d --build to rebuild the image If using Python, run pdm install --prod to install any new or updated packages Update any installed terminal hooks Overwrite the previous script / module file with the updated version (if the git pull didn't do this automatically); be sure to update the new script / module with any configuration changes you made to the old one Start a new shell session","title":"Updating"},{"location":"updating/#updating-terminal_sync","text":"Use git pull to get the latest updates or download an updated zip archive from GitHub Update the server If using Docker, run docker-compose up -d --build to rebuild the image If using Python, run pdm install --prod to install any new or updated packages Update any installed terminal hooks Overwrite the previous script / module file with the updated version (if the git pull didn't do this automatically); be sure to update the new script / module with any configuration changes you made to the old one Start a new shell session","title":"Updating terminal_sync"},{"location":"usage/","text":"Usage The entire point of terminal_sync is to log shell commands automatically. Therefore, once the server is setup and the hooks are registered , no further action is necessary. That said, the following are a few runtime options that can enhance the user experience. Specify the Source Host Set the environment variable SRC_HOST to the host where your activity will originate. This value will appear in the Source field on GhostWriter and is particularly useful when operating over a SOCKS proxy or tunnel. If the client (i.e., hook) environment is different than the terminal_sync server environment (e.g., if using Docker), the client-side value will override the server-side value. If this value is not provided, terminal_sync will default to the hostname and IP of the host where the server is running. If using Docker, this will be the container. Add a Description terminal_sync allows users to (optionally) specify a description at the end of each command. Anything that appears after the string specified by the gw_description_token setting will be extracted and used as the Description attribute of the log entry. Note : This token must begin with a # so that Bash and PowerShell interpret it, and everything that follows, as a comment and don't attempt to execute the description text. Log Ad-hoc Commands Since the gw_description_token inherently triggers logging, users can append this string to any command, with or without additional text, to force an individual command to be logged. Enable / Disable terminal_sync Run Disable-TermSync to temporarily disable terminal_sync once hooks are registered for that session. To re-enable it, run Enable-TermSync . These commands set a flag that is checked when each hook is run, skipping the hook logic if disabled, and consequently only affect the current session. To permanently disable terminal_sync, delete or comment out the line in ~/.bashrc or your PowerShell $PROFILE that loads the hooks. Adjust Console Output at Runtime Both the Bash script and PowerShell module contain a configuration setting that allows users to set the default console output; however, this can be changed (temporarily) for a session, using the Set-TermSyncVersbosity command. In Bash, simply run Set-TermSyncVersbosity ; this will print a list of display settings and prompt you for a number. Enter the number that matches your preferred setting. In PowerShell, type Set-TermSyncVerbosity , followed by a space, then press Tab to cycle through the available options. Press Enter to select your preferred setting. Export Logs to GhostWriter CSV Any log entries that cannot be sent to GhostWriter successfully, such as due to a configuration or connectivity issue, will be saved (local to the server) in JSON format. The configuration setting termsync_save_all_local can be used to override this behavior and save all entries, even those logged to GhostWriter successfully. If the GhostWrite URL or API keys are not provided, this setting is automatically enabled to prevent accidental loss of logs. On shutdown, the terminal_sync server will attempt to export these saved logs to a timestamped CSV file that can be imported to GhostWriter. The export_csv.py script can also be run manually to generate a CSV file without stopping the server. # Usage: # export_csv.py [-h] -l LOG_DIR [-o OUTPUT_DIR] # Example: python src/terminal_sync/export_csv.py -l log_archive","title":"Usage"},{"location":"usage/#usage","text":"The entire point of terminal_sync is to log shell commands automatically. Therefore, once the server is setup and the hooks are registered , no further action is necessary. That said, the following are a few runtime options that can enhance the user experience.","title":"Usage"},{"location":"usage/#specify-the-source-host","text":"Set the environment variable SRC_HOST to the host where your activity will originate. This value will appear in the Source field on GhostWriter and is particularly useful when operating over a SOCKS proxy or tunnel. If the client (i.e., hook) environment is different than the terminal_sync server environment (e.g., if using Docker), the client-side value will override the server-side value. If this value is not provided, terminal_sync will default to the hostname and IP of the host where the server is running. If using Docker, this will be the container.","title":"Specify the Source Host"},{"location":"usage/#add-a-description","text":"terminal_sync allows users to (optionally) specify a description at the end of each command. Anything that appears after the string specified by the gw_description_token setting will be extracted and used as the Description attribute of the log entry. Note : This token must begin with a # so that Bash and PowerShell interpret it, and everything that follows, as a comment and don't attempt to execute the description text.","title":"Add a Description"},{"location":"usage/#log-ad-hoc-commands","text":"Since the gw_description_token inherently triggers logging, users can append this string to any command, with or without additional text, to force an individual command to be logged.","title":"Log Ad-hoc Commands"},{"location":"usage/#enable-disable-terminal_sync","text":"Run Disable-TermSync to temporarily disable terminal_sync once hooks are registered for that session. To re-enable it, run Enable-TermSync . These commands set a flag that is checked when each hook is run, skipping the hook logic if disabled, and consequently only affect the current session. To permanently disable terminal_sync, delete or comment out the line in ~/.bashrc or your PowerShell $PROFILE that loads the hooks.","title":"Enable / Disable terminal_sync"},{"location":"usage/#adjust-console-output-at-runtime","text":"Both the Bash script and PowerShell module contain a configuration setting that allows users to set the default console output; however, this can be changed (temporarily) for a session, using the Set-TermSyncVersbosity command. In Bash, simply run Set-TermSyncVersbosity ; this will print a list of display settings and prompt you for a number. Enter the number that matches your preferred setting. In PowerShell, type Set-TermSyncVerbosity , followed by a space, then press Tab to cycle through the available options. Press Enter to select your preferred setting.","title":"Adjust Console Output at Runtime"},{"location":"usage/#export-logs-to-ghostwriter-csv","text":"Any log entries that cannot be sent to GhostWriter successfully, such as due to a configuration or connectivity issue, will be saved (local to the server) in JSON format. The configuration setting termsync_save_all_local can be used to override this behavior and save all entries, even those logged to GhostWriter successfully. If the GhostWrite URL or API keys are not provided, this setting is automatically enabled to prevent accidental loss of logs. On shutdown, the terminal_sync server will attempt to export these saved logs to a timestamped CSV file that can be imported to GhostWriter. The export_csv.py script can also be run manually to generate a CSV file without stopping the server. # Usage: # export_csv.py [-h] -l LOG_DIR [-o OUTPUT_DIR] # Example: python src/terminal_sync/export_csv.py -l log_archive","title":"Export Logs to GhostWriter CSV"}]}